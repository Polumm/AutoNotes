# AutoNotes: Transcribe, Summarize & Chat with Your Own LLM

**AutoNotes** is a privacy-first, local-first web app that helps you quickly extract insights from audio or video files using [Whisper](https://github.com/openai/whisper) for transcription and [Ollama](https://ollama.com) for large language model (LLM) summarization and refinement.

Upload a file, get an instant transcript and summary, and continue chatting with the LLM to refine, translate, or extract key points â€” all running locally to protect your data.

---

## âœ¨ Features

- ğŸ”’ **Privacy-First**: Everything runs locally using Whisper and Ollama.
- ğŸ§  **Smart Summaries**: Automatically generate summaries from audio/video content.
- ğŸ’¬ **Conversational Refinement**: Ask follow-up questions or refine summaries via chat.
- ğŸ–¥ï¸ **Web UI**: Simple drag-and-drop interface with streaming LLM replies.
- âš¡ **Fast Transcription**: Use Whisper with GPU acceleration (in `flask run`) or CPU (via Docker).

![App Screenshot on deepseek model](app/static/2025_03_25_224416.jpg)

---

## ğŸ› ï¸ Setup Instructions

### 1. Install Ollama

Follow the [Ollama installation guide](https://ollama.com/download) for your OS.

Then download a compatible LLM:

```bash
ollama pull deepseek-r1:14b
```

> You can use another model if you prefer â€” just update `LLM_MODEL` in `config.py`.

---

## ğŸ§ª Development Mode (Whisper on GPU)

Requires Python 3.10+ and GPU support.

```bash
# Clone and setup
git clone https://github.com/your-username/autonotes
cd autonotes

# Create virtual environment
python -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run the Flask app
flask run
```

Visit: [http://localhost:5000](http://localhost:5000)

---

## ğŸ³ Docker Mode (CPU only)

> This mode uses Whisper with CPU (slower) but simplifies setup via Docker.

### 1. Build & Run

```bash
docker-compose up --build
```

Then open: [http://localhost:5000](http://localhost:5000)

---

## ğŸ“ Project Structure

```
autonotes/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ summarize.py
â”‚   â”‚   â””â”€â”€ chat.py
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â””â”€â”€ static/         # (Optional for future assets)
â”œâ”€â”€ config.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”§ Configuration

Edit `config.py` or override via environment variables:

```python
OLLAMA_API = os.getenv("OLLAMA_API", "http://localhost:11434/api/chat")
LLM_MODEL = os.getenv("LLM_MODEL", "deepseek-r1:14b")
WHISPER_MODEL_DIR = os.getenv("WHISPER_MODEL_DIR", "./models/whisper")
```

---

## ğŸ’¡ Use Cases

- ğŸ§‘â€ğŸ“ Students summarizing lectures
- ğŸ™ï¸ Podcasters extracting show notes
- ğŸ“½ï¸ YouTubers creating video abstracts
- ğŸ’¼ Professionals capturing meeting takeaways

---

## ğŸ“£ Contributions

Feel free to open issues or pull requests to improve the tool!

---

### ğŸ§  Powered by:

- [Whisper by OpenAI](https://github.com/openai/whisper)
- [Ollama](https://ollama.com)
- [Flask](https://flask.palletsprojects.com/)